{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#      MODEL BUILDING PROCESSING\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = pd.read_csv(r'./data/coords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Data\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns = [\"class\"])\n",
    "y = dataset[\"class\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
    "# reassingn index and columns\n",
    "X_train2.columns = X_train.columns.values\n",
    "X_train2.index = X_train.index.values\n",
    "X_train_scaled = X_train2\n",
    "\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test))\n",
    "X_test2.columns = X_test.columns.values\n",
    "X_test2.index = X_test.index.values\n",
    "X_test_scaled = X_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to check perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def perfomance_check(name: str):\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, pos_label='positive',\n",
    "                                           average='micro')\n",
    "    rec = recall_score(y_test, y_pred, pos_label='positive',\n",
    "                                           average='micro')\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='positive',\n",
    "                                           average='micro')\n",
    "\n",
    "    model_results = pd.DataFrame([[name, acc, prec, rec, f1]],\n",
    "                   columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    \n",
    "    return results.append(model_results, ignore_index = True)\n",
    "\n",
    "results = pd.DataFrame(columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# CLASSIFICATIONS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\"The max_iter was reached which means \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_classifier = LogisticRegression(random_state = 0, penalty = 'l1', solver='saga')\n",
    "LR_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = LR_classifier.predict(X_test)\n",
    "\n",
    "results = perfomance_check('Linear Regression (Lasso)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K-Nearest Neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN_classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "KNN_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = KNN_classifier.predict(X_test)\n",
    "\n",
    "results = perfomance_check('K-Nearest Neighbours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVML_classifier = SVC(random_state = 0, kernel = 'linear')\n",
    "SVML_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = SVML_classifier.predict(X_test)\n",
    "\n",
    "results = perfomance_check('SVM (Linear)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernal SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "K_SVM_classifier = SVC(random_state = 0, kernel = 'rbf')\n",
    "K_SVM_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = K_SVM_classifier.predict(X_test)\n",
    "\n",
    "results = perfomance_check('SVM (RBF)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB_classifier = GaussianNB()\n",
    "NB_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = NB_classifier.predict(X_test)\n",
    "\n",
    "results = perfomance_check('Naive Bayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DTC_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "DTC_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = DTC_classifier.predict(X_test)\n",
    "\n",
    "results = perfomance_check('Decision Tree Classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\nC:\\Users\\sijal\\anaconda3\\envs\\vision\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1295: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_classifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\n",
    "                                    criterion = 'entropy')\n",
    "RF_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = RF_classifier.predict(X_test)\n",
    "\n",
    "results = perfomance_check('Random Forest (n=100)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-93cf1c79bcb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mxgb_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mxgb_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_classifier = XGBClassifier()\n",
    "xgb_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "results = perfomance_check('XGBoost ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-49830f52be5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mCB_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mCB_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCB_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "CB_classifier = CatBoostClassifier()\n",
    "CB_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = CB_classifier.predict(X_test)\n",
    "\n",
    "results = perfomance_check('CatBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          Model  Accuracy  Precision    Recall  F1 Score\n",
       "0     Linear Regression (Lasso)  0.937984   0.937984  0.937984  0.937984\n",
       "1          K-Nearest Neighbours  1.000000   1.000000  1.000000  1.000000\n",
       "2                  SVM (Linear)  0.984496   0.984496  0.984496  0.984496\n",
       "3                     SVM (RBF)  0.883721   0.883721  0.883721  0.883721\n",
       "4                   Naive Bayes  0.984496   0.984496  0.984496  0.984496\n",
       "5  Decision Tree Classification  1.000000   1.000000  1.000000  1.000000\n",
       "6         Random Forest (n=100)  1.000000   1.000000  1.000000  1.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression (Lasso)</td>\n      <td>0.937984</td>\n      <td>0.937984</td>\n      <td>0.937984</td>\n      <td>0.937984</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>K-Nearest Neighbours</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVM (Linear)</td>\n      <td>0.984496</td>\n      <td>0.984496</td>\n      <td>0.984496</td>\n      <td>0.984496</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SVM (RBF)</td>\n      <td>0.883721</td>\n      <td>0.883721</td>\n      <td>0.883721</td>\n      <td>0.883721</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Naive Bayes</td>\n      <td>0.984496</td>\n      <td>0.984496</td>\n      <td>0.984496</td>\n      <td>0.984496</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Decision Tree Classification</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Random Forest (n=100)</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# MODEL SELECTION\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation\n",
    "---\n",
    "* Conside which model perform the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lst = [LR_classifier,    # 0\n",
    "             KNN_classifier,   # 1\n",
    "             SVML_classifier,  # 2\n",
    "             K_SVM_classifier, # 3\n",
    "             NB_classifier,    # 4\n",
    "             DTC_classifier,   # 5\n",
    "             RF_classifier,    # 6\n",
    "             xgb_classifier,   # 7\n",
    "             CB_classifier]    # 8\n",
    "msg = []\n",
    "for i in range(len(model_lst)):\n",
    "    accuracies = cross_val_score(estimator =model_lst[i] , X = X_train, y = y_train, cv = 10)\n",
    "    msg.append(f\"Model Accuracy {i}: %0.3f (+/- %0.3f)\" % (accuracies.mean(), accuracies.std() * 2))\n",
    "    \n",
    "for i in msg:\n",
    "    print(i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in msg:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the script to compare result with prediction\n",
    "comparision = pd.DataFrame(columns = ['Result', 'Prediction'])\n",
    "comparision.Prediction = pd.Series(y_pred)\n",
    "comparision.Result = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning\n",
    "---\n",
    "Base on the critera we can choose what type of parameter tuning algorithm to use.\n",
    "#### Grid Search: Entropy \n",
    "* Meant to maximize the information content (in random forest we maximize the info. at every split)\n",
    "* pip install joblib\n",
    "* update joblib if there are some problem in GridSearch\n",
    "\n",
    "#### Grid Search: Gini\n",
    "* Meant to minimize the probability of mislabelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input parameters\n",
    "---\n",
    "* Input different parameter based on the \"Model\" that you tring to tune\n",
    "* Look into documentaion of specific algorithm for avaiable parameters\n",
    "* Based on the best found parametes, slim down the range of the setting and test again\n",
    ". \n",
    "         ***1st setting***\n",
    "         {\"max_depth\": [3, None], \n",
    "         \"max_features\": [1, 5, 10], \n",
    "         'min_samples_split': [2, 5, 10],\n",
    "         'min_samples_leaf': [1, 5, 10], \n",
    "         \"bootstrap\": [True, False],  \n",
    "         \"criterion\": [\"entropy\"]}\n",
    ".        \n",
    "          ***Slimed down version***\n",
    "          {\"max_depth\": [None],\n",
    "              \"max_features\": [3, 5, 7],\n",
    "              'min_samples_split': [8, 10, 12],\n",
    "              'min_samples_leaf': [1, 2, 3],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"entropy\"]}\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 5, 10],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 5, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"entropy\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search: Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search_entropy = GridSearchCV(estimator = RF_classifier, # Make sure classifier points to the RF model\n",
    "                           param_grid = parameters,\n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "t0 = time.time()    # RECORD THE DURATION ALGORITHM TOOK\n",
    "grid_search = grid_search.fit(X_train, y_train) \n",
    "t1 = time.time()\n",
    "print(\"Took %0.2f seconds\" % (t1 - t0))\n",
    "\n",
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy, rf_best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search: Gini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 5, 10],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 5, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search_gini = GridSearchCV(estimator = classifier, # Make sure classifier points to the RF model\n",
    "                           param_grid = parameters,\n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"Took %0.2f seconds\" % (t1 - t0))\n",
    "\n",
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy, rf_best_parameters"
   ]
  },
  {
   "source": [
    "## Save Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search_entropy, f)\n",
    "\n",
    "with open('body_language.pkl', 'rb') as f:\n",
    "    grid_search_entropy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Test Set\n",
    "---\n",
    "* Base on the best grid result test model, using its specific grid_serach parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Correct grid_search 'entropy' or 'gini'\n",
    "y_pred = grid_search_entropy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sn.set(font_scale=2.8)\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize = (50,40))\n",
    "sn.heatmap(corr, annot=True,mask=mask);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.concat([y_test, users], axis = 1).dropna()\n",
    "final_results['predictions'] = y_pred\n",
    "final_results = final_results[['entry_id', 'e_signed', 'predictions']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0db74b6cf253f3d1752866f1a73259b874beb65d95511e62ec1f648eb0403f7e3",
   "display_name": "Python 3.8.8 64-bit ('vision': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}